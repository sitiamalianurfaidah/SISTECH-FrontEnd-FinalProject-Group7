# Recommendation Engine for Jobs, Courses, Majors, Career, and Job Articles

# Overview
This project builds a comprehensive recommendation engine designed to guide users in exploring suitable jobs, educational courses, university majors, career paths, and job-related articles. By integrating diverse datasets and utilizing text-based similarity techniques, the system helps users navigate through various options based on their interests or background. The goal is to provide a more personalized and informative experience for individuals making academic or career decisions, especially students or fresh graduates. The recommendation results are generated by analyzing both user inputs and content features, ensuring relevant and practical suggestions across different domains.

---
## Features
- Career recommendation based on user’s RIASEC result, major (if user is a highschooler), interests, and skills
- Job recommendation based on career match
- Course & Certification recommendations based on career match
- Majors & University recommendations based on career match (if user is a highschooler)
- Career outlook & articles

---
## Scraping Methods & Data Sources

The scraping methods in this project involve collecting data from various online sources to build a comprehensive dataset for recommendations. The key scraping processes include:

1. **Job Data**:
   - Source: LinkedIn Job API
   - Method: Web scraping using API dan BeautifulSoup to extract job postings.

2. **Course Data**:
   - Source: edX API
   - Method: API integration and web scraping to gather course details.

3. **University Majors**:
   - Source: BAN-PT and QS World University Rankings 2026
   - Method: Scraping major offerings, program details, and rankings.

4. **Career Articles**:
   - Source: Google Custom Search API
   - Method: Fetching articles related to career trends, job market outlook, and employment forecasts.

5. **Career Data**:
   - Source: O*NET Online
   - Method: API integration to fetch career data, including job descriptions, required skills, and career outlooks based on RIASEC scores, user's major, skills, and interests.

---
## Vectorization
The vectorization process in this project uses Sentence Transformers, a state-of-the-art model for generating dense vector representations of text. This method is particularly effective for capturing semantic meaning, making it ideal for tasks like recommendation systems. The steps include:

1. **Text Embedding**: Input text data is converted into dense vector representations using the Sentence Transformers model (`all-MiniLM-L6-v2`).
2. **Normalization**: The generated vectors are normalized to unit length to ensure consistency in cosine similarity calculations.
3. **Storage**: The embeddings are stored in a FAISS index, which allows for efficient similarity searches and retrievals.

---
## Vector Database

The vector database in this project is implemented using FAISS (Facebook AI Similarity Search), a library designed for efficient similarity search and clustering of dense vectors. It is used to store and retrieve vectorized representations of text data, enabling fast and accurate similarity calculations. The key features include:

1. **Indexing**: The dense vector representations generated during the vectorization process are stored in a FAISS index. This index allows for efficient similarity searches using methods like cosine similarity.
2. **Storage**: The FAISS index is saved to disk, ensuring that it can be quickly loaded and reused without the need to recompute embeddings.
3. **Scalability**: FAISS is optimized for handling large-scale datasets, making it suitable for this project's diverse and extensive data sources.

By leveraging FAISS, the system ensures that recommendations are generated quickly and accurately, even when dealing with large volumes of data.

---
## Similarity

The similarity calculation in this project is based on cosine similarity, a metric that measures the cosine of the angle between two vectors in a multi-dimensional space. This approach is particularly effective for comparing text embeddings generated by models like Sentence Transformers. The steps include:

1. **Embedding Comparison**: The embeddings of the query text and the dataset are compared.
2. **Cosine Similarity Formula**: The similarity score is calculated using the formula:
   \[
   \text{similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
   \]
   where \(A\) and \(B\) are the embedding vectors.
3. **Ranking**: The results are ranked based on their similarity scores, with higher scores indicating greater relevance.

---
## API
1. O*NET Web Services API:

Used for career recommendations based on RIASEC scores.

Endpoints:
- /ws/mnm/interestprofiler/careers: Fetches careers matching the RIASEC scores.
- /ws/mnm/careers/{career_code}/report: Retrieves detailed reports for specific careers.
- Requires authentication using a username and password, encoded in the request headers.

2. Google Custom Search API:

Used to fetch job-related articles and trends.

Endpoint:
- /customsearch/v1: Searches for articles based on a query string.

Requires an API key and a search engine ID for authentication.

---
## Folder Structure

```bash
SISTECH-MLOps-FinalProject-Group7/
│
├── main.py                           # Main FastAPI application
├── 01_scrapping.ipynb                # Data scraping notebook
├── 02_preprocessing.ipynb            # Data preprocessing notebook
├── 03_translate_csv.py               # CSV translation script
├── 04_methods_evaluation.ipynb       # Model evaluation notebook
├── app/                              # Core application modules
│   ├── data_processing.py            # Data processing utilities
│   ├── recommender.py                # Main recommendation logic
│   ├── text_preprocessing.py         # Text preprocessing functions
│   ├── embeddings/                   # FAISS vector indices
│   │   ├── careers_st.index          # Career embeddings index
│   │   ├── courses_st.index          # Course embeddings index
│   │   ├── jobs_st.index             # Job embeddings index
│   │   └── major_st.index            # Major embeddings index
│   └── models/                       # Trained models
│       └── st_model/                 # Sentence Transformer model
├── model_output_files/               # Sample API output files
│   ├── output_get_job_articles.json
│   ├── output_recommend_careers.json
│   ├── output_recommend_courses.json
│   ├── output_recommend_jobs.json
│   └── output_recommend_programs.json
├── preprocessed/                     # Processed data files
│   ├── edx_courses.json              # Processed course data
│   ├── linkedin_jobs.json            # Processed job data
│   ├── major_final.csv               # Processed major data
│   ├── major_final.json              # Major data in JSON format
│   └── onet_careers.json             # Processed career data
├── scrape_result/                    # Raw scraped data
│   ├── edx_courses.csv               # Raw course data
│   ├── jurusan_result.csv            # Raw major data
│   ├── linkedin_jobs.csv             # Raw job data
│   ├── onet_careers.json             # Raw career data
│   └── universitas_indonesia_qs.csv  # University rankings data
├── translated/                       # Translated data files
│   └── major_final.csv               # Translated major data
├── .env                              # Environment variables (ignored by git)
├── .gitignore                        # Git ignore rules
├── requirements.txt                  # Python dependencies
└── README.md                         # Project documentation
```


---
## Environment Variables (.env)

Before running the application, ensure that the `.env` file is properly configured with the following environment variables:

- `ONET_USERNAME`: Your O*NET API username 
- `ONET_PASSWORD`: Your O*NET API password 
- `GOOGLE_API_KEY`: Your Google API key 
- `SEARCH_ENGINE_ID`: Your Google Custom Search Engine ID

These variables are required for accessing the O*NET and Google APIs used in the project.

---
## Running the Application

Before starting the application, generate the FAISS indices by running the following command:

```bash
python app/data_processing.py
```

This will process the data and create the necessary vector indices for recommendations.

Then, start the application using:

```bash
uvicorn main:app --reload
```

This will make the FastAPI application accessible at `http://127.0.0.1:8000`.

## Testing the Endpoints

Once the application is running, you can test the following endpoints:

- **`/recommend-careers`**: Accepts RIASEC scores and returns career recommendations.
  - Example: `http://127.0.0.1:8000/recommend-careers`
  - Input Example
   ```json
   {
   "in_highschool": false,
   "skills": "Statistical analysis\\nRisk assessment\\nFinancial modeling\\nData interpretation\\nProblem-solving\\nAttention to detail",
   "interests": "Financial risk analysis\\nInsurance modeling\\nMathematical modeling in finance\\nForecasting and simulation\\nPension & retirement planning\\nData-driven decision making",
   "major": "Actuarial Science",
   "r": 5,
   "i": 15,
   "a": 0,
   "s": 0,
   "e": 0,
   "c": 15,
   "top_n": 3,
   "request_id": 1
   }
   ```

- **`/recommend-jobs`**: Accepts a query string and returns job recommendations.
  - Example: `http://127.0.0.1:8000/recommend-jobs`
  - Input Example (use the `recommendations['text']` field from `/recommend-careers` endpoint)
   ```json
   {
  "query": "actuary actuarial analyst actuary consulting actuary pricing actuary analyze statistical data...",
  "top_n": 3,
  "request_id": 1
   }

   ```

- **`/recommend-courses`**: Accepts a query string and returns course recommendations.
  - Example: `http://127.0.0.1:8000/recommend-courses`
  - Input Example (use the `recommendations['text']` field from `/recommend-careers` endpoint)
   ```json
   {
  "query": "actuary actuarial analyst actuary consulting actuary pricing actuary analyze statistical data...",
  "top_n": 3,
  "request_id": 1
   }

- **`/recommend-programs`**: Accepts a query string and returns university major or program recommendations.
  - Example: `http://127.0.0.1:8000/recommend-programs`
  - Input Example (use the `recommendations['text']` field from `/recommend-careers` endpoint)
   ```json
   {
  "query": "actuary actuarial analyst actuary consulting actuary pricing actuary analyze statistical data...",
  "top_n": 3,
  "request_id": 1
   }

- **`/get-job-articles`**: Accepts a query string and returns job-related articles.
  - Example: `http://127.0.0.1:8000/get-job-articles`
  - Input Example (use the `recommendations['title']` field from `/recommend-careers` endpoint)
   ```json
   {
  "query": "Actuary",
  "top_n": 3,
  "request_id": 1
   }

- **`/health`**: A health check endpoint to verify the API is running.
  - Example: `http://127.0.0.1:8000/health`

---

## Contributors
- [Amelia Wibisono](https://github.com/pengwen101)
- [Deira Aisya Refani](https://github.com/deiraaisyar)